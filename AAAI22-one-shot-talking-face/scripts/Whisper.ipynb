{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63b4c35",
   "metadata": {},
   "source": [
    "## Creating Audio File\n",
    "\n",
    "Checkout https://beta.elevenlabs.io/history for full log of audio creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e508c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./play_kitten\"\n",
    "mp3_file_name = file_name + \".mp3\"\n",
    "wav_file_name = file_name + \".wav\"\n",
    "\n",
    "generate_new_audio = False\n",
    "name_of_voice = \"Bella\"\n",
    "text = \"I love you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e5c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'voice_id': 'EXAVITQu4vr4xnSDxMaL', 'name': 'Bella', 'samples': None, 'category': 'premade', 'fine_tuning': {'is_allowed_to_fine_tune': False, 'fine_tuning_requested': False, 'finetuning_state': 'not_started', 'verification_attempts': None, 'verification_attempts_count': 0}, 'labels': {}, 'preview_url': 'https://storage.googleapis.com/eleven-public-prod/premade/voices/EXAVITQu4vr4xnSDxMaL/04365bce-98cc-4e99-9f10-56b60680cda9.mp3', 'available_for_tiers': [], 'settings': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'EXAVITQu4vr4xnSDxMaL'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get voice ID\n",
    "import requests\n",
    "\n",
    "r1 = requests.get('https://api.elevenlabs.io/v1/voices')\n",
    "resp = r1.json()\n",
    "rid = \"\"\n",
    "for voice in resp[\"voices\"]:\n",
    "    if voice[\"name\"] == name_of_voice:\n",
    "        print(voice)\n",
    "        rid = voice[\"voice_id\"]\n",
    "        break;\n",
    "rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5589f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio file, minimize runs cost money\n",
    "import json\n",
    "\n",
    "if generate_new_audio:\n",
    "    url = \"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}\".format(voice_id=rid)\n",
    "    print(url)\n",
    "    headers = {'xi-api-key': \"aa42307ce6bfbefcfd2abd4d8634127b\"}\n",
    "    payload = {\n",
    "      \"text\": text,\n",
    "      \"voice_settings\": {\n",
    "        \"stability\": 0.3,\n",
    "        \"similarity_boost\": 0.75\n",
    "      }\n",
    "    }\n",
    "\n",
    "    r2 = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "    print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7a7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and play audio file\n",
    "import os\n",
    "\n",
    "if generate_new_audio:\n",
    "    with open(mp3_file_name, 'wb') as f:\n",
    "        f.write(r2.content)\n",
    "\n",
    "    os.system(\"mpg123 \" + mp3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63bf150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert mp3 to wav                                                            \n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "if generate_new_audio:\n",
    "    sound = AudioSegment.from_mp3(mp3_file_name)\n",
    "    sound.export(wav_file_name, format=\"wav\")\n",
    "\n",
    "    # test sound\n",
    "    song = AudioSegment.from_wav(wav_file_name)\n",
    "    play(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbc91a",
   "metadata": {},
   "source": [
    "## Generate phonemes\n",
    "- Uses https://github.com/m-bain/whisperX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0226e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jfuentes/Projects/infinitenews/AAAI22-one-shot-talking-face/scripts\n",
      "File name: ./play_kitten.wav\n",
      "Base name: play_kitten\n"
     ]
    }
   ],
   "source": [
    "# no extension, must be wav\n",
    "import os\n",
    "cwd = os.getcwd() #pwd\n",
    "print(cwd)\n",
    "\n",
    "audio_file_name = wav_file_name\n",
    "base_audio_file_name = os.path.splitext(os.path.basename(audio_file_name))[0]\n",
    "print(\"File name:\", audio_file_name)\n",
    "print(\"Base name:\", base_audio_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8e7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jfuentes/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/torchaudio/_internal/module_utils.py:99: UserWarning: Failed to import soundfile. 'soundfile' backend is not available.\n",
      "  warnings.warn(\"Failed to import soundfile. 'soundfile' backend is not available.\")\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "\n",
    "device = \"cpu\" \n",
    "# transcribe with original whisper\n",
    "model = whisperx.load_model(\"large\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcdf496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jfuentes/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/whisperx/transcribe.py:83: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load audio: ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n  built with Apple clang version 14.0.0 (clang-1400.0.29.202)\n  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/5.1.2_5 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-neon\n  libavutil      57. 28.100 / 57. 28.100\n  libavcodec     59. 37.100 / 59. 37.100\n  libavformat    59. 27.100 / 59. 27.100\n  libavdevice    59.  7.100 / 59.  7.100\n  libavfilter     8. 44.100 /  8. 44.100\n  libswscale      6.  7.100 /  6.  7.100\n  libswresample   4.  7.100 /  4.  7.100\n  libpostproc    56.  6.100 / 56.  6.100\n./play_kitten.wav: No such file or directory\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/whisperx/audio.py:42\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# This launches a subprocess to decode audio while down-mixing and resampling as necessary.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Requires the ffmpeg CLI and `ffmpeg-python` package to be installed.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 42\u001b[0m         \u001b[43mffmpeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms16le\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpcm_s16le\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mffmpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-nostdin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_stdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_stderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ffmpeg\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/ffmpeg/_run.py:325\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(stream_spec, cmd, capture_stdout, capture_stderr, input, quiet, overwrite_output)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, out, err)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, err\n",
      "\u001b[0;31mError\u001b[0m: ffmpeg error (see stderr output for detail)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;66;03m# before alignment\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# load alignment model and metadata\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/whisperx/transcribe.py:90\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, mel, **decode_options)\u001b[0m\n\u001b[1;32m     87\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mis_multilingual:\n",
      "File \u001b[0;32m~/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/whisperx/audio.py:111\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[0;34m(audio, n_mels)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[1;32m    114\u001b[0m window \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhann_window(N_FFT)\u001b[38;5;241m.\u001b[39mto(audio\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/whisperx/audio.py:47\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     41\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     42\u001b[0m         ffmpeg\u001b[38;5;241m.\u001b[39minput(file, threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;241m.\u001b[39moutput(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms16le\u001b[39m\u001b[38;5;124m\"\u001b[39m, acodec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpcm_s16le\u001b[39m\u001b[38;5;124m\"\u001b[39m, ac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ar\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;241m.\u001b[39mrun(cmd\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-nostdin\u001b[39m\u001b[38;5;124m\"\u001b[39m], capture_stdout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, capture_stderr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ffmpeg\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfrombuffer(out, np\u001b[38;5;241m.\u001b[39mint16)\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32768.0\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to load audio: ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n  built with Apple clang version 14.0.0 (clang-1400.0.29.202)\n  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/5.1.2_5 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-neon\n  libavutil      57. 28.100 / 57. 28.100\n  libavcodec     59. 37.100 / 59. 37.100\n  libavformat    59. 27.100 / 59. 27.100\n  libavdevice    59.  7.100 / 59.  7.100\n  libavfilter     8. 44.100 /  8. 44.100\n  libswscale      6.  7.100 /  6.  7.100\n  libswresample   4.  7.100 /  4.  7.100\n  libpostproc    56.  6.100 / 56.  6.100\n./play_kitten.wav: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result = model.transcribe(audio_file_name)\n",
    "\n",
    "print(result[\"segments\"]) # before alignment\n",
    "\n",
    "# load alignment model and metadata\n",
    "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "\n",
    "# align whisper output\n",
    "result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file_name, device)\n",
    "\n",
    "# print(result_aligned[\"segments\"]) # after alignment\n",
    "end = time.time()\n",
    "print(\"Time\", end - start)\n",
    "\n",
    "result_aligned[\"word_segments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86387c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a501c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = [\"that's\", \"Help! \", \"multiverse\", \"cat\", \"permit\", \"surprise\", \",whales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c840961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "try:\n",
    "    arpabet = nltk.corpus.cmudict.dict()\n",
    "except LookupError:\n",
    "    nltk.download('cmudict')\n",
    "    arpabet = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1074b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import lru_cache\n",
    "from itertools import product as iterprod\n",
    "\n",
    "def cleanWord(word):\n",
    "    regex = r\"[^\\w\\']\"\n",
    "    return re.sub(regex, \"\", word).lower()\n",
    "\n",
    "def arpabetWithoutNumbers(word):\n",
    "    list_of_phones = []\n",
    "    for phones in arpabet[word]:\n",
    "        new_phones = [\"\".join(filter(lambda x: x.isalpha(), phone)) for phone in phones]\n",
    "        list_of_phones.append(new_phones)\n",
    "    return list_of_phones\n",
    "\n",
    "def wordbreak(s):\n",
    "    s = cleanWord(s)\n",
    "    if s in arpabet:\n",
    "        return arpabetWithoutNumbers(s)\n",
    "    middle = len(s)/2\n",
    "    partition = sorted(list(range(len(s))), key=lambda x: (x-middle)**2-x)\n",
    "    for i in partition:\n",
    "        pre, suf = (s[:i], s[i:])\n",
    "        if pre in arpabet and wordbreak(suf) is not None:\n",
    "            return [x+y for x,y in iterprod(arpabetWithoutNumbers(pre), wordbreak(suf))]\n",
    "    return None\n",
    "\n",
    "# Example words: \n",
    "for w in test_words:\n",
    "    print(wordbreak(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4466c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41b536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterToPhone(word, phones):\n",
    "    # print(\"LTP\", word, phones)\n",
    "    if word == \"\":\n",
    "        return []\n",
    "\n",
    "    for i in reversed(range(1, len(word))):\n",
    "        for j in range(0, len(word) - i + 1):\n",
    "            subword = word[j:i+j]\n",
    "            cur_possible_phones = wordbreak(subword)\n",
    "            #For when has contractions\n",
    "            if not cur_possible_phones:\n",
    "                print(\"Skipping\", i, j, subword, cur_possible_phones)\n",
    "                continue\n",
    "            else:\n",
    "                cur_possible_phones = cur_possible_phones + [[subword.upper()]]\n",
    "                print(i, j, subword, cur_possible_phones)\n",
    "\n",
    "            for cur_phones in cur_possible_phones:\n",
    "                extra_length = len(phones) - len(cur_phones)\n",
    "#                 print(\"EL\", extra_length)\n",
    "                if extra_length > 0:\n",
    "                    for a in range(0, extra_length + 1):\n",
    "                        subphones_end = len(phones) - (extra_length - a)\n",
    "                        subphones = phones[a:subphones_end]\n",
    "                        if len(subphones) != len(cur_phones):\n",
    "                            print(\"Lengths not equal....\")\n",
    "                        #print(subphones, cur_phones)\n",
    "                        if subphones == cur_phones:\n",
    "                            #print(\"MATCH\", subword, subphones)\n",
    "                            first = letterToPhone(word[0:j], phones[0:a])\n",
    "                            cur = letterToPhone(subword, subphones)\n",
    "                            last = letterToPhone(word[i+j:], phones[subphones_end:])\n",
    "                            # print(\"LTP Complete\", first, cur, last)\n",
    "                            return first + cur + last\n",
    "                    \n",
    "    return [[word, phones]]\n",
    "\n",
    "for segment in result_aligned[\"word_segments\"]:\n",
    "    word = segment[\"text\"]\n",
    "\n",
    "# for word in test_words:\n",
    "    print(word)\n",
    "    print(letterToPhone(word, wordbreak(word)[0]))\n",
    "    print([word, wordbreak(word)[0]], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'text': 'Good', 'start': 0.10120481927710842, 'end': 0.32385542168674697},\n",
    "# INTO\n",
    "# [\n",
    "#     {\n",
    "#         \"word\": \"sil\",\n",
    "#         \"phones\": [\n",
    "#             {\n",
    "#                 \"ph\": \"SIL\",\n",
    "#                 \"bg\": 0,\n",
    "#                 \"ed\": 126\n",
    "#             }\n",
    "#         ]\n",
    "#     },\n",
    "#     {\n",
    "#         \"word\": \"YOU\",\n",
    "#         \"phones\": [\n",
    "#             {\n",
    "#                 \"ph\": \"Y\",\n",
    "#                 \"bg\": 126,\n",
    "#                 \"ed\": 138\n",
    "#             },\n",
    "#             {\n",
    "#                 \"ph\": \"UW\",\n",
    "#                 \"bg\": 138,\n",
    "#                 \"ed\": 141\n",
    "#             }\n",
    "#         ]\n",
    "#     },\n",
    "from math import trunc\n",
    "\n",
    "def makeSegment(word, phones, start, end):\n",
    "    total = end - start\n",
    "    time_per_phone = trunc(total / len(phones))\n",
    "#     print(total, time_per_phone)\n",
    "    expanded_phones = [{\"ph\": phone, \"bg\": start + (i * time_per_phone), \"ed\": start + ((i + 1) * time_per_phone)} for i, phone in enumerate(phones)]\n",
    "    return {\"word\": word, \"phones\": expanded_phones}\n",
    "\n",
    "def makeSil(start, end):\n",
    "    return {\"word\": \"sil\", \"phones\": [{\"ph\": \"SIL\", \"bg\": start, \"ed\": end}]}\n",
    "  \n",
    "all_phonemes = []\n",
    "for segment in result_aligned[\"word_segments\"]:\n",
    "    word = segment[\"text\"]\n",
    "    #Get rid of numbers in phones\n",
    "    phonemes = wordbreak(word)[0]\n",
    "    print(phonemes)\n",
    "    start_time = trunc(segment[\"start\"] * 100)\n",
    "    end_time = trunc(segment[\"end\"] * 100)\n",
    "    \n",
    "    if len(all_phonemes) > 0:\n",
    "        last = all_phonemes[-1]\n",
    "        last_end = last[\"phones\"][-1][\"ed\"]\n",
    "        if start_time - last_end > 5:\n",
    "            sil = makeSil(last_end, start_time)\n",
    "            all_phonemes.append(sil)\n",
    "        else:\n",
    "            start_time = last_end\n",
    "    else:\n",
    "        sil = makeSil(0, start_time)\n",
    "        all_phonemes.append(sil)\n",
    "        \n",
    "    segment = makeSegment(word, phonemes, start_time, end_time)\n",
    "    all_phonemes.append(segment)\n",
    "\n",
    "all_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37dd754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to  ../samples/phonemes/kitten.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"../samples/phonemes/{name}.json\".format(name=base_audio_file_name)\n",
    "print(\"Writing to \", file_name)\n",
    "with open(file_name, 'w') as f1:\n",
    "    json.dump(all_phonemes, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4326767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'sil', 'phones': [{'ph': 'SIL', 'bg': 0, 'ed': 10}]},\n",
       " {'word': 'I', 'phones': [{'ph': 'AY', 'bg': 10, 'ed': 16}]},\n",
       " {'word': 'love',\n",
       "  'phones': [{'ph': 'L', 'bg': 16, 'ed': 23},\n",
       "   {'ph': 'AH', 'bg': 23, 'ed': 30},\n",
       "   {'ph': 'V', 'bg': 30, 'ed': 37}]},\n",
       " {'word': 'you.',\n",
       "  'phones': [{'ph': 'Y', 'bg': 37, 'ed': 43},\n",
       "   {'ph': 'UW', 'bg': 43, 'ed': 49}]}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_phonemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627009c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f700232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fdb2d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:1337/api/modules/1?populate=Image1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': {'id': 1,\n",
       "  'attributes': {'Text1': \"Good evening everyone and welcome to this special report. As you know, we’ve been tracking a strange uptick in activity in the multiverse - and as we feared, it appears that space whales have been invading our universe through a rift in the multiverse. \\n\\nThese massive creatures, which can range in size from the size of a small ship to larger than a mountain, are wreaking havoc on the balance of the multiverse. What's worse is that they seem to be coming from a totally different dimension, one that our scientists didn't even know existed until now.\\n\\nWe’ve seen some strange things in the multiverse before, but never anything as awe-inspiring and destructive as these space whales. They’ve already destroyed several planets and star systems, and it looks like they’re only getting started. \\n\\nThe multiverse is in a state of crisis, but thankfully our scientists are working around the clock to try and close the rift and prevent any more of these creatures from entering our universe. We won’t know for sure if they’re successful until it’s too late, so in the meantime, we’re all on high alert. \\n\\nStay tuned for more updates and stay safe out there, everyone. This is Margot Robbie, signing off.\",\n",
       "   'Text2': 'help',\n",
       "   'createdAt': '2023-03-01T05:40:17.228Z',\n",
       "   'updatedAt': '2023-03-01T05:52:29.538Z',\n",
       "   'publishedAt': '2023-03-01T05:50:28.978Z',\n",
       "   'Image1': {'data': {'id': 3,\n",
       "     'attributes': {'name': 'Alice.jpg',\n",
       "      'alternativeText': None,\n",
       "      'caption': None,\n",
       "      'width': 1024,\n",
       "      'height': 1024,\n",
       "      'formats': {'thumbnail': {'name': 'thumbnail_Alice.jpg',\n",
       "        'hash': 'thumbnail_Alice_dc4aa08c52',\n",
       "        'ext': '.jpg',\n",
       "        'mime': 'image/jpeg',\n",
       "        'path': None,\n",
       "        'width': 156,\n",
       "        'height': 156,\n",
       "        'size': 5.88,\n",
       "        'url': '/uploads/thumbnail_Alice_dc4aa08c52.jpg'},\n",
       "       'medium': {'name': 'medium_Alice.jpg',\n",
       "        'hash': 'medium_Alice_dc4aa08c52',\n",
       "        'ext': '.jpg',\n",
       "        'mime': 'image/jpeg',\n",
       "        'path': None,\n",
       "        'width': 750,\n",
       "        'height': 750,\n",
       "        'size': 65.36,\n",
       "        'url': '/uploads/medium_Alice_dc4aa08c52.jpg'},\n",
       "       'small': {'name': 'small_Alice.jpg',\n",
       "        'hash': 'small_Alice_dc4aa08c52',\n",
       "        'ext': '.jpg',\n",
       "        'mime': 'image/jpeg',\n",
       "        'path': None,\n",
       "        'width': 500,\n",
       "        'height': 500,\n",
       "        'size': 35.56,\n",
       "        'url': '/uploads/small_Alice_dc4aa08c52.jpg'},\n",
       "       'large': {'name': 'large_Alice.jpg',\n",
       "        'hash': 'large_Alice_dc4aa08c52',\n",
       "        'ext': '.jpg',\n",
       "        'mime': 'image/jpeg',\n",
       "        'path': None,\n",
       "        'width': 1000,\n",
       "        'height': 1000,\n",
       "        'size': 101.6,\n",
       "        'url': '/uploads/large_Alice_dc4aa08c52.jpg'}},\n",
       "      'hash': 'Alice_dc4aa08c52',\n",
       "      'ext': '.jpg',\n",
       "      'mime': 'image/jpeg',\n",
       "      'size': 104.91,\n",
       "      'url': '/uploads/Alice_dc4aa08c52.jpg',\n",
       "      'previewUrl': None,\n",
       "      'provider': 'local',\n",
       "      'provider_metadata': None,\n",
       "      'createdAt': '2023-03-01T05:40:02.272Z',\n",
       "      'updatedAt': '2023-03-01T05:40:02.272Z'}}}}},\n",
       " 'meta': {}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1de9ac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS not available because the current MacOS version is not 12.3+ and/or you do not have an MPS-enabled device on this machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6aad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c59c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db7e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09a563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7e085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f5154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90109a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

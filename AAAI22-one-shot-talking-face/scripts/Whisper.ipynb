{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63b4c35",
   "metadata": {},
   "source": [
    "## Creating Audio File\n",
    "\n",
    "Checkout https://beta.elevenlabs.io/history for full log of audio creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e508c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_voice = \"Bella\"\n",
    "text = \"I love you\"\n",
    "file_name = \"./temp\"\n",
    "mp3_file_name = file_name + \".mp3\"\n",
    "wav_file_name = file_name + \".wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1e5c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'voice_id': 'EXAVITQu4vr4xnSDxMaL', 'name': 'Bella', 'samples': None, 'category': 'premade', 'fine_tuning': {'is_allowed_to_fine_tune': False, 'fine_tuning_requested': False, 'finetuning_state': 'not_started', 'verification_attempts_count': 0}, 'labels': {}, 'preview_url': 'https://storage.googleapis.com/eleven-public-prod/premade/voices/EXAVITQu4vr4xnSDxMaL/04365bce-98cc-4e99-9f10-56b60680cda9.mp3', 'available_for_tiers': [], 'settings': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'EXAVITQu4vr4xnSDxMaL'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get voice ID\n",
    "import requests\n",
    "\n",
    "r1 = requests.get('https://api.elevenlabs.io/v1/voices')\n",
    "resp = r1.json()\n",
    "rid = \"\"\n",
    "for voice in resp[\"voices\"]:\n",
    "    if voice[\"name\"] == name_of_voice:\n",
    "        print(voice)\n",
    "        rid = voice[\"voice_id\"]\n",
    "        break;\n",
    "rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5589f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.elevenlabs.io/v1/text-to-speech/EXAVITQu4vr4xnSDxMaL\n"
     ]
    }
   ],
   "source": [
    "# Get audio file, minimize runs cost money\n",
    "import json\n",
    "\n",
    "url = \"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}\".format(voice_id=rid)\n",
    "print(url)\n",
    "headers = {'xi-api-key': \"aa42307ce6bfbefcfd2abd4d8634127b\"}\n",
    "payload = {\n",
    "  \"text\": text,\n",
    "  \"voice_settings\": {\n",
    "    \"stability\": 0.3,\n",
    "    \"similarity_boost\": 0.75\n",
    "  }\n",
    "}\n",
    "\n",
    "r2 = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c7a7580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "High Performance MPEG 1.0/2.0/2.5 Audio Player for Layers 1, 2 and 3\n",
      "\tversion 1.31.2; written and copyright by Michael Hipp and others\n",
      "\tfree software (LGPL) without any warranty but with best wishes\n",
      "\n",
      "Directory: ./\n",
      "Playing MPEG stream 1 of 1: temp.mp3 ...\n",
      "\n",
      "MPEG 1.0 L III cbr64 44100 mono\n",
      "\n",
      "[0:00] Decoding of temp.mp3 finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and play audio file\n",
    "import os\n",
    "\n",
    "with open(mp3_file_name, 'wb') as f:\n",
    "    f.write(r2.content)\n",
    "\n",
    "os.system(\"mpg123 \" + mp3_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a63bf150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/g8/b65pczf97pb17p1_zrldsm500000gn/T/tmpt9m7e2pp.wav':\n",
      "  Duration: 00:00:00.84, bitrate: 706 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, 1 channels, s16, 705 kb/s\n",
      "   0.67 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   0.70 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r",
      "   0.73 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    }
   ],
   "source": [
    "# convert mp3 to wav                                                            \n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "\n",
    "sound = AudioSegment.from_mp3(mp3_file_name)\n",
    "sound.export(wav_file_name, format=\"wav\")\n",
    "\n",
    "# test sound\n",
    "song = AudioSegment.from_wav(wav_file_name)\n",
    "play(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbc91a",
   "metadata": {},
   "source": [
    "## Generate phonemes\n",
    "- Uses https://github.com/m-bain/whisperX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f0226e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jfuentes/Projects/infinitenews/AAAI22-one-shot-talking-face/scripts\n",
      "File name: ./temp.wav\n",
      "Base name: temp.wav\n"
     ]
    }
   ],
   "source": [
    "# no extension, must be wav\n",
    "import os\n",
    "cwd = os.getcwd() #pwd\n",
    "print(cwd)\n",
    "\n",
    "audio_file_name = wav_file_name\n",
    "base_audio_file_name = os.path.basename(audio_file_name)\n",
    "print(\"File name:\", audio_file_name)\n",
    "print(\"Base name:\", base_audio_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b8e7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "\n",
    "device = \"cpu\" \n",
    "# transcribe with original whisper\n",
    "model = whisperx.load_model(\"large\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fcdf496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jfuentes/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/whisperx/transcribe.py:83: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 0.64, 'text': ' I love you.', 'tokens': [50364, 286, 959, 291, 13, 50396], 'temperature': 0.0, 'avg_logprob': -0.5376458849225726, 'compression_ratio': 0.5789473684210527, 'no_speech_prob': 0.029172642156481743}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jfuentes/Projects/infinitenews/AAAI22-one-shot-talking-face/venv/lib/python3.9/site-packages/whisperx/alignment.py:302: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  char_segments_arr = per_seg_grp.apply(lambda x: x.reset_index(drop = True)).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'I', 'start': 0.1032258064516129, 'end': 0.16516129032258065},\n",
       " {'text': 'love', 'start': 0.2064516129032258, 'end': 0.3716129032258064},\n",
       " {'text': 'you.', 'start': 0.4129032258064516, 'end': 0.49548387096774194}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.transcribe(audio_file_name)\n",
    "\n",
    "print(result[\"segments\"]) # before alignment\n",
    "\n",
    "# load alignment model and metadata\n",
    "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "\n",
    "# align whisper output\n",
    "result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file_name, device)\n",
    "\n",
    "# print(result_aligned[\"segments\"]) # after alignment\n",
    "result_aligned[\"word_segments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86387c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a501c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c840961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "try:\n",
    "    arpabet = nltk.corpus.cmudict.dict()\n",
    "except LookupError:\n",
    "    nltk.download('cmudict')\n",
    "    arpabet = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1074b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DH', 'AE1', 'T', 'S']]\n",
      "[['HH', 'EH1', 'L', 'P']]\n",
      "[['M', 'AH1', 'L', 'T', 'IY0', 'V', 'ER1', 'S']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from functools import lru_cache\n",
    "from itertools import product as iterprod\n",
    "\n",
    "def cleanWord(word):\n",
    "    regex = r\"[^\\w\\']\"\n",
    "    return re.sub(regex, \"\", word).lower()\n",
    "\n",
    "def wordbreak(s):\n",
    "    s = cleanWord(s)\n",
    "    if s in arpabet:\n",
    "        return arpabet[s]\n",
    "    middle = len(s)/2\n",
    "    partition = sorted(list(range(len(s))), key=lambda x: (x-middle)**2-x)\n",
    "    for i in partition:\n",
    "        pre, suf = (s[:i], s[i:])\n",
    "        if pre in arpabet and wordbreak(suf) is not None:\n",
    "            return [x+y for x,y in iterprod(arpabet[pre], wordbreak(suf))]\n",
    "    return None\n",
    "\n",
    "# Example words: \n",
    "for w in [\"that's\", \"Help! \", \"multiverse\"]:\n",
    "    print(wordbreak(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6ad6670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AY']\n",
      "['L', 'AH', 'V']\n",
      "['Y', 'UW']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'sil', 'phones': [{'ph': 'SIL', 'bg': 0, 'ed': 10}]},\n",
       " {'word': 'I', 'phones': [{'ph': 'AY', 'bg': 10, 'ed': 16}]},\n",
       " {'word': 'love',\n",
       "  'phones': [{'ph': 'L', 'bg': 16, 'ed': 23},\n",
       "   {'ph': 'AH', 'bg': 23, 'ed': 30},\n",
       "   {'ph': 'V', 'bg': 30, 'ed': 37}]},\n",
       " {'word': 'you.',\n",
       "  'phones': [{'ph': 'Y', 'bg': 37, 'ed': 43},\n",
       "   {'ph': 'UW', 'bg': 43, 'ed': 49}]}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {'text': 'Good', 'start': 0.10120481927710842, 'end': 0.32385542168674697},\n",
    "# INTO\n",
    "# [\n",
    "#     {\n",
    "#         \"word\": \"sil\",\n",
    "#         \"phones\": [\n",
    "#             {\n",
    "#                 \"ph\": \"SIL\",\n",
    "#                 \"bg\": 0,\n",
    "#                 \"ed\": 126\n",
    "#             }\n",
    "#         ]\n",
    "#     },\n",
    "#     {\n",
    "#         \"word\": \"YOU\",\n",
    "#         \"phones\": [\n",
    "#             {\n",
    "#                 \"ph\": \"Y\",\n",
    "#                 \"bg\": 126,\n",
    "#                 \"ed\": 138\n",
    "#             },\n",
    "#             {\n",
    "#                 \"ph\": \"UW\",\n",
    "#                 \"bg\": 138,\n",
    "#                 \"ed\": 141\n",
    "#             }\n",
    "#         ]\n",
    "#     },\n",
    "from math import trunc\n",
    "\n",
    "def makeSegment(word, phones, start, end):\n",
    "    total = end - start\n",
    "    time_per_phone = trunc(total / len(phones))\n",
    "#     print(total, time_per_phone)\n",
    "    expanded_phones = [{\"ph\": phone, \"bg\": start + (i * time_per_phone), \"ed\": start + ((i + 1) * time_per_phone)} for i, phone in enumerate(phones)]\n",
    "    return {\"word\": word, \"phones\": expanded_phones}\n",
    "\n",
    "def makeSil(start, end):\n",
    "    return {\"word\": \"sil\", \"phones\": [{\"ph\": \"SIL\", \"bg\": start, \"ed\": end}]}\n",
    "  \n",
    "all_phonemes = []\n",
    "for segment in result_aligned[\"word_segments\"]:\n",
    "    word = segment[\"text\"]\n",
    "    #Get rid of numbers in phones\n",
    "    phonemes = [\"\".join(filter(lambda x: x.isalpha(), phone)) for phone in wordbreak(word)[0]]\n",
    "    print(phonemes)\n",
    "    start_time = trunc(segment[\"start\"] * 100)\n",
    "    end_time = trunc(segment[\"end\"] * 100)\n",
    "    \n",
    "    if len(all_phonemes) > 0:\n",
    "        last = all_phonemes[-1]\n",
    "        last_end = last[\"phones\"][-1][\"ed\"]\n",
    "        if start_time - last_end > 5:\n",
    "            sil = makeSil(last_end, start_time)\n",
    "            all_phonemes.append(sil)\n",
    "        else:\n",
    "            start_time = last_end\n",
    "    else:\n",
    "        sil = makeSil(0, start_time)\n",
    "        all_phonemes.append(sil)\n",
    "        \n",
    "    segment = makeSegment(word, phonemes, start_time, end_time)\n",
    "    all_phonemes.append(segment)\n",
    "\n",
    "all_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "37dd754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to  ../samples/phonemes/kitten_full.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"../samples/phonemes/{name}.json\".format(name=audio_file_name)\n",
    "print(\"Writing to \", file_name)\n",
    "f1 = open(file_name, 'w')\n",
    "json.dump(all_phonemes, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4326767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'sil', 'phones': [{'ph': 'SIL', 'bg': 0, 'ed': 10}]},\n",
       " {'word': 'I', 'phones': [{'ph': 'AY', 'bg': 10, 'ed': 16}]},\n",
       " {'word': 'love',\n",
       "  'phones': [{'ph': 'L', 'bg': 16, 'ed': 23},\n",
       "   {'ph': 'AH', 'bg': 23, 'ed': 30},\n",
       "   {'ph': 'V', 'bg': 30, 'ed': 37}]},\n",
       " {'word': 'you.',\n",
       "  'phones': [{'ph': 'Y', 'bg': 37, 'ed': 43},\n",
       "   {'ph': 'UW', 'bg': 43, 'ed': 49}]}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627009c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f700232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2d9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9ac94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6aad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c59c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db7e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09a563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7e085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f5154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90109a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
